{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ec8de0d-75af-43df-abf7-05d4e744ca0f",
   "metadata": {},
   "source": [
    "# Hugging Face Transformers 微调训练入门\n",
    "\n",
    "本示例将介绍基于 Transformers 实现模型微调训练的主要流程，包括：\n",
    "- 数据集下载\n",
    "- 数据预处理\n",
    "- 训练超参数配置\n",
    "- 训练评估指标设置\n",
    "- 训练器基本介绍\n",
    "- 实战训练\n",
    "- 模型保存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31188fb-d5ed-438d-911c-6ce92489003a",
   "metadata": {},
   "source": [
    "## YelpReviewFull 数据集\n",
    "\n",
    "**Hugging Face 数据集：[ YelpReviewFull ](https://huggingface.co/datasets/yelp_review_full)**\n",
    "\n",
    "### 数据集摘要\n",
    "\n",
    "Yelp评论数据集包括来自Yelp的评论。它是从Yelp Dataset Challenge 2015数据中提取的。\n",
    "\n",
    "### 支持的任务和排行榜\n",
    "文本分类、情感分类：该数据集主要用于文本分类：给定文本，预测情感。\n",
    "\n",
    "### 语言\n",
    "这些评论主要以英语编写。\n",
    "\n",
    "### 数据集结构\n",
    "\n",
    "#### 数据实例\n",
    "一个典型的数据点包括文本和相应的标签。\n",
    "\n",
    "来自YelpReviewFull测试集的示例如下：\n",
    "\n",
    "```json\n",
    "{\n",
    "    'label': 0,\n",
    "    'text': 'I got \\'new\\' tires from them and within two weeks got a flat. I took my car to a local mechanic to see if i could get the hole patched, but they said the reason I had a flat was because the previous patch had blown - WAIT, WHAT? I just got the tire and never needed to have it patched? This was supposed to be a new tire. \\\\nI took the tire over to Flynn\\'s and they told me that someone punctured my tire, then tried to patch it. So there are resentful tire slashers? I find that very unlikely. After arguing with the guy and telling him that his logic was far fetched he said he\\'d give me a new tire \\\\\"this time\\\\\". \\\\nI will never go back to Flynn\\'s b/c of the way this guy treated me and the simple fact that they gave me a used tire!'\n",
    "}\n",
    "```\n",
    "\n",
    "#### 数据字段\n",
    "\n",
    "- 'text': 评论文本使用双引号（\"）转义，任何内部双引号都通过2个双引号（\"\"）转义。换行符使用反斜杠后跟一个 \"n\" 字符转义，即 \"\\n\"。\n",
    "- 'label': 对应于评论的分数（介于1和5之间）。\n",
    "\n",
    "#### 数据拆分\n",
    "\n",
    "Yelp评论完整星级数据集是通过随机选取每个1到5星评论的130,000个训练样本和10,000个测试样本构建的。总共有650,000个训练样本和50,000个测试样本。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0600af-4896-4612-954b-7c8fe8772b30",
   "metadata": {},
   "source": [
    "## 下载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0550f91e-caed-4c01-aea9-142022d22d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b6326b8-d6c0-482d-9ceb-f03beee0105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 65w条训练数据 5w条测试数据\n",
    "\n",
    "dataset = load_dataset('yelp_review_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea54e5ac-32e4-4d8b-949b-832aa1635b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 650000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "889587f2-31ca-43d0-9e99-6cbbfe511bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 4,\n",
       " 'text': \"dr. goldberg offers everything i look for in a general practitioner.  he's nice and easy to talk to without being patronizing; he's always on time in seeing his patients; he's affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first.  really, what more do you need?  i'm sitting here trying to think of any complaints i have about him, but i'm really drawing a blank.\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffc15d2b-2cba-498e-8997-7ab395fe82f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70cf5ccd-4255-40c3-92ab-23bbec8f0143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_elements(dataset, num_examples=10):\n",
    "    # '如果随机抽取的长度如果大于dataset长度则报错'\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    # picks = []\n",
    "    # for _ in range(num_examples):\n",
    "    #     # 随机在0-数据长度之间选择一个\n",
    "    #     pick = random.randint(0,dataset.num_rows-1)\n",
    "    #     # 如果在picks中出现过，则从新选择一个,直到没有在picks中出现过\n",
    "    #     while pick in picks:\n",
    "    #         pick = random.randint(0,dataset.num_rows-1)\n",
    "    #     picks.append(pick)\n",
    "    picks = np.random.choice(dataset.num_rows-1, size=num_examples, replace=False).tolist()\n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    \n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i:typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b669fbc-1b8a-48f0-8479-91deb9cee24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 star</td>\n",
       "      <td>Horrible preschool. Teachers are lazy and the kids do not learn much. We pulled our son out this year.  We realize now why they lost so many kids last year. School has bad leadership and fired teachers because of low enrollment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 star</td>\n",
       "      <td>I been waiting for this place to open for 4 months, and I am severely disappointed. The service was terrible, we waited 45 minutes and never got our food, but noticed people who ordered the same thing get theirs(sounds like the order process needs some work) \\n\\nI asked for a refund and the manager didn't apologize and didn't say anything, but to add insult to injury the manager charged us for the drinks!!!!(sounds like the manager needs to learn some customer service 101) \\n\\nOn the way out I overheard people talking that they been waiting 15 minutes for 1/2 a sandwich and some people got the wrong order but didn't complain because they been waiting long as well and were just hungry. Please  Mind you that this place wasn't that busy. \\n\\nI plan on never eating here again.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5 stars</td>\n",
       "      <td>I heard of Liberty Tech and Tire through a facebook page called \\\"Huntridge Neighborhood\\\", I did not realize that the business had change from a European parts establishment to Liberty Tech and Tire (repair shop).  Because of the outstanding rave about Harun and Liberty Tech and Tire, I took a chance and stopped by for an oil change... I knew that my brakes were not in the best shape but wasn't ready to fork out the money to have them replaced just yet.  \\nWell needless to say, due to the great deal that Huran offered me, they changed the booth drums and disc on the back axle for only $99.00 plus tax and he threw in the oil change with the deal.   That's not only great customer service but a real neighborhood business that definitely gets my support and business.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 stars</td>\n",
       "      <td>OMG!  Delicious, decadent, and worth every penny.\\n\\nWe started with the chop and heirloom tomato salads. Theynwere excellent.  Foie gras torchon was also very good as an app.\\n\\nFor dinner my wife and I shared the chili rubbed bone-in double rib eye.  We ordered this based on the review from the Food Network show \\\"The Best Thing I Ever Ate.\\\". It did not disappoint!  They chili rub made very a very tasty crust, and the onions, jalapenos, and peppers were a nice twist.  Definitely not your typical steakhouse fare.\\n\\nWe will definitely go back.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4 stars</td>\n",
       "      <td>Great sushi restaurant inside of Red Rock Casino.  Kinda pricey but a great place for a date night if you're wanting to splurge a little.  The \\\"Top 6 Roll\\\" is my favorite and my husband loves the \\\"Jeffrey Roll.\\\"  Great selection of sake if you're into that...my hubby always tries something different each time we go.  Great selection of specials that are $8 and under to allow you to order a variety of things without killing your bill.\\n\\nThey used to have these to-die-for mussels in a spicy coconut broth but they got rid of them because not enough people were ordering them.  Wish they would bring them back. \\n\\nDecor is super modern and trendy, service has always been great and it's open pretty late on Fridays and weekends.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4 stars</td>\n",
       "      <td>I loved this car wash..once I figured out how to get into it (easiest to enter from 44th street).  No Cheesecake Factory menu that takes 20 minutes to read and figure out what the difference is between the $4 wash, the $7 wash, the $12 wash...you get the idea.\\n\\nI took my husband's vehicle in while he was out of town.  I know, I'm nice like that.  $25 for an SUV complete wash.  This is a true hand wash.  No conveyor belts or automated water squirter things.  Guys with hoses who do a really good job.  They use compressed air to dry, and I watched them go over and over the car to make sure nothing was missed.  I was hard-pressed to find any water streaks.  It can be slow, but it's worth it.\\n\\nThe only downside is the waiting area is outside (covered), so I don't anticipate his vehicle's next wash until November.  Luckily, my 10 year old vehicle has no aversions to machine washes.  But then again, It would be lucky to get washed before November anyway.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3 stars</td>\n",
       "      <td>I want to give this place 5 stars, since I've recommended it to all sorts of people.  But that was based upon an early experience I've simply not been able to replicate.\\n\\nYou see, when you say 'Rhumbar' to me, I hear Caribbean Rum Bar.  The first time I saw this place it was new.  Semi-empty.  Afternoon on a warmer Nevada day.  Smartly selected music (like Stephen Marley's 'Mind Control' and a latin cover of a U2 song) was carefully piped in... but not in a way that upstaged my Cruzan Rum inspired drink.\\n\\n(Let me back up.  Any 'rum' place which won't serve Cruzan Rum, in my opinion, isn't a rum place at all.  Bacardi?  Bring Advil.  Cruzan Rum?  Leave the weed behind.)\\n\\nAnd so the first time I was here I had an delightful drink with fresh fruit in it.  Overpriced?  In the real world, kinda, on the strip, not at all.  It was a groovy place 'to chill' as the kids say and you could simply hang for hours if you wanted.  Understand you're outside in the Mirage palms and waterfalls and such.  It's simply lovely.\\n\\nAnd so I've tried to come back to this place ever since this experience.  And some idiot has given it a semi-clubby make over.  LOUD DJ.  KAREOKE.  SPORTS BAR BIG TVS.  \\n\\nWTF, Rhumbar?  \\n\\nMirage:  you now have two DEAFENING DANCE CLUBS on premise.  That INK thing and now 1 OAK.  Let the bouncer boys and half naked girls 'chill' in those subwoofered strobe holes.  But please... PLEASE... let the 'rest of us' have a place to hang out with only moderate mayhem?\\n\\nThat's why I've giving the Rhumbar 3 stars.  It's identity crisis is inexplicable.  If Mirage really wants people to see a big party outside (which may be a smart move) then do this for me.  At night, when the pool closes, re-open it as 'The Japonais Lounge', with new lounge chairs and hanging lamps.  A place to have a drink and retain your ear drums.  I'd love it if you had to be over 40 to get in -- hee hee.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2 star</td>\n",
       "      <td>It's never a good sign when you wait 15 minutes for a server to come to you. I was greeted with \\\"What would you like to drink\\\" No hello, welcome, sorry for your wait. \\n\\nFood was nothing to write home about. I had the California chicken sandwich and it was very salty. \\n\\nThis was my second time here and I won't return!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5 stars</td>\n",
       "      <td>Great local place!! Check it out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1 star</td>\n",
       "      <td>My husband and I along with his family were walking around after an awesome lunch at Noodle no. 9 and came back to the Bellagio to go hang out at the Bellagio Cafe for a little while before heading out to the airport to catch our flights back home. As we were walking through the lobby of the Bellagio, they were taking down their garden ornaments, and there was places that were cut off and two men who were security funneling and stopping traffic through roped off areas that people were walking in and out of.\\n\\nAs we were walking through the tall man said to us \\\"Do YOU PEOPLE not understand when a man tells you to stop that you have to stop?!\\\" -- to which I didn't ever remember the other guy telling us we had to stop, and if he did it was an honest mistake as I was at the front of our group and I wasn't particularly feeling too well as I was a bit anemic at the time. He continued to be rude to us as I walked past and I told him that he \\\"didn't have to be so rude\\\" and we continued onward. The use of the phrase \\\"you people\\\" particularly bothered me because my husband and his mother are Korean, and his younger sister is half Korean, while her father (my husband's step-dad) is a white male.\\n\\nJust the way the guy said it to us, and REPEATED it over and over again as we kept walking, each time more loud and more rude didn't sit well with me. So I scuttled ahead to find a place where I could sit down, because I was so upset at just how rude that guy was. People make honest mistakes.. if we walked through and the other guy told us to stop which somehow all 5 of us seemed to have not heard, then we would have apologized, and that should have been the end of it. We were all so upset with how this guy treated us, that we decided to head back to the hotel lobby and just leave for the airport -- well to do so, we had to go back where that guy was.\\n\\nAs we were approaching people were allowed to walk through the pathway and we were going with the flow of traffic. He then stopped us again, even though people on the other side were being let through (like traffic on a two-way road) -- which made absolutely no sense. It was pretty clear that he was singling us out because of the indecent before hand. My husband's father told the guy that the situation was ridiculous, and continued to walk forward as people were still being allowed to walk through on the left side of us. Once he did that the \\\"security guard\\\" (as he called himself) physically put his hands on Jason's father and pushed him. My husband's father then told him that his actions were uncalled for and was physical assault to which the guard responded by pushing my husband's father further back with his chest and getting up in his face repeating that he was a security gaurd, and he had the right to put his hands on him and kept telling us to \\\"look at the badge\\\" meaning his name tag with his name Michael on it and where he was from - San Bernardino, CA. My husband's mother was appalled and told him to get his hands off of her husband, and the guy touched me telling me to get back even though I never even moved from my original position, nor did I try to even start a confrontation.\\n\\nWe had done nothing wrong. We were on a FAMILY vacation in Vegas. None of us have ever been involved in any crimes, nor were we being aggressive in any manor. It was uncalled for and made for a horrible ending to our vacation.\\n\\nWe then waited to file a complaint with the head of security, in which we got an apology -- but he said the manor would be looked into. And the more we had talked to him, the more it seemed apparent that they probably had other incidents happen with Michael. Unfortunately we weren't able to file a formal complaint on paper with the hotel as we had to leave to catch our flights back home.\\n\\nNot only that, but in the beginning of our vacation, my husband and I went to check into our room with our confirmation email printed out (which had 2 confirm numbers for each room that his father had reserved) and the lady at the check out desk told us that we couldn't check in because it was only under my husband's father's name -- although we told her we had ANOTHER confirmation number, that also had my husband under another room's list and the woman was rude and said \\\"I don't care, that's only a piece of paper. It doesn't mean anything.\\\" and when we went to another teller, they were more than nice to hear us out and we were able to get our room.\\n\\nOther than those two incidents, we had nice clean rooms and had a good time otherwise. However since the security incident happened the way it did, never again will we be staying with the Bellagio....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(dataset['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbb5b6b-474b-4a37-bfc8-d3ccfa99c22f",
   "metadata": {},
   "source": [
    "## 预处理数据\n",
    "\n",
    "下载数据集到本地后，使用 Tokenizer 来处理文本，对于长度不等的输入数据，可以使用填充（padding）和截断（truncation）策略来处理。\n",
    "\n",
    "Datasets 的 `map` 方法，支持一次性在整个数据集上应用预处理函数。\n",
    "\n",
    "下面使用填充到最大长度的策略，处理整个数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89d32c0f-24df-4a1f-bf63-909d35bfb6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ad57601-91e7-44a4-9ae0-7b0578c0f058",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02cf5235-1809-4eb9-ae47-cd52a866e06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c39add39-873c-473b-9318-051c62a70318",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5e53258-b62f-448d-b307-072239be9d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 star</td>\n",
       "      <td>This cafe is located on the main casino floor of Binions Hotel and Casino in Fremont Street, Las Vegas.\\n\\nI had the pulled pork sandwich, which was more like a bbq sauce sandwich with pulled pork garnish.  But hey, at least they toasted the bun.  \\n\\nThe price seemed a little stiff at close to $8.  But the coffee is good and strong.\\n\\nAll in all, not a place I'm likely to return to, unless it's for a fast cup of joe.</td>\n",
       "      <td>[101, 1188, 17287, 1110, 1388, 1113, 1103, 1514, 14330, 1837, 1104, 21700, 5266, 4556, 1105, 14773, 1107, 13359, 26642, 1715, 117, 5976, 6554, 119, 165, 183, 165, 183, 2240, 1125, 1103, 1865, 19915, 14327, 117, 1134, 1108, 1167, 1176, 170, 171, 1830, 4426, 14313, 14327, 1114, 1865, 19915, 176, 1813, 21816, 119, 1252, 23998, 117, 1120, 1655, 1152, 17458, 1174, 1103, 171, 3488, 119, 165, 183, 165, 183, 1942, 4638, 3945, 1882, 170, 1376, 11111, 1120, 1601, 1106, 109, 129, 119, 1252, 1103, 3538, 1110, 1363, 1105, 2012, 119, 165, 183, 165, 183, 1592, 2339, 1107, 1155, 117, 1136, 170, ...]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(tokenized_datasets['train'], num_examples=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d94fe3-6794-4103-9a63-e22726d1ec8c",
   "metadata": {},
   "source": [
    "### 数据抽样\n",
    "\n",
    "使用 1000 个数据样本，在 BERT 上演示小规模训练（基于 Pytorch Trainer）\n",
    "\n",
    "`shuffle()`函数会随机重新排列列的值。如果您希望对用于洗牌数据集的算法有更多控制，可以在此函数中指定generator参数来使用不同的numpy.random.Generator。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6de11e5b-3474-4e0a-bd00-b95ee2a6b38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc690a40-af4d-496d-ae67-515b73c0fbc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_train_dataset.num_rows, small_eval_dataset.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230596f7-eb0c-43f0-bf9e-4a944a9afefe",
   "metadata": {},
   "source": [
    "## 微调训练配置\n",
    "\n",
    "### 加载 BERT 模型\n",
    "\n",
    "警告通知我们正在丢弃一些权重（`vocab_transform` 和 `vocab_layer_norm` 层），并随机初始化其他一些权重（`pre_classifier` 和 `classifier` 层）。在微调模型情况下是绝对正常的，因为我们正在删除用于预训练模型的掩码语言建模任务的头部，并用一个新的头部替换它，对于这个新头部，我们没有预训练的权重，所以库会警告我们在用它进行推理之前应该对这个模型进行微调，而这正是我们要做的事情。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "407777bc-ab63-4af8-9e13-c8b035a60f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7130c597-3306-4e12-b570-54080f5a0843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-cased', num_labels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77de2766-1b89-4a33-ba6c-6094b57975e3",
   "metadata": {},
   "source": [
    "### 训练超参数（TrainingArguments）\n",
    "\n",
    "完整配置参数与默认值：https://huggingface.co/docs/transformers/v4.36.1/en/main_classes/trainer#transformers.TrainingArguments\n",
    "\n",
    "源代码定义：https://github.com/huggingface/transformers/blob/v4.36.1/src/transformers/training_args.py#L161\n",
    "\n",
    "**最重要配置：模型权重保存路径(output_dir)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "279f4915-bfae-498d-a090-6c980abd1746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40175704-a8b9-459f-9b4d-ff20c9f34707",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"models/bert-base-cased-finetune-yelp\"\n",
    "# logging_steps 默认值为500，根据我们的训练数据和步长，将其设置为100\n",
    "training_args = TrainingArguments(output_dir=model_dir,\n",
    "                                  per_device_train_batch_size=16,\n",
    "                                  num_train_epochs=5,\n",
    "                                  logging_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c40e6a1-a21c-42e4-adbe-aba170cd133d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=passive,\n",
      "log_on_each_node=True,\n",
      "logging_dir=models/bert-base-cased-finetune-yelp\\runs\\Jan28_21-34-52_AnMin,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=100,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=5,\n",
      "optim=adamw_hf,\n",
      "output_dir=models/bert-base-cased-finetune-yelp,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=models/bert-base-cased-finetune-yelp,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=steps,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 完整的超参数配置\n",
    "print(training_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2350153-1004-4443-bbd0-18f100ff1116",
   "metadata": {},
   "source": [
    "### 训练过程中的指标评估（Evaluate)\n",
    "\n",
    "**[Hugging Face Evaluate 库](https://huggingface.co/docs/evaluate/index)** 支持使用一行代码，获得数十种不同领域（自然语言处理、计算机视觉、强化学习等）的评估方法。 当前支持 **完整评估指标：https://huggingface.co/evaluate-metric**\n",
    "\n",
    "训练器（Trainer）在训练过程中不会自动评估模型性能。因此，我们需要向训练器传递一个函数来计算和报告指标。 \n",
    "\n",
    "Evaluate库提供了一个简单的准确率函数，您可以使用`evaluate.load`函数加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1182a85e-c82d-4b07-97f0-d5285af5a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d1c9063-8020-4dee-87de-1e09e5a5860c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd5bf0e-24b3-4cae-8d48-526d3fe336ed",
   "metadata": {},
   "source": [
    "接着，调用 `compute` 函数来计算预测的准确率。\n",
    "\n",
    "在将预测传递给 compute 函数之前，我们需要将 logits 转换为预测值（**所有Transformers 模型都返回 logits**）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c09fbac8-dcc7-4d19-ae11-32aed09742e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb8d88e-2475-4d59-9084-1aca00d9479e",
   "metadata": {},
   "source": [
    "#### 训练过程指标监控\n",
    "\n",
    "通常，为了监控训练过程中的评估指标变化，我们可以在`TrainingArguments`指定`evaluation_strategy`参数，以便在 epoch 结束时报告评估指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11cdbc08-9ec4-4a30-989d-3d68bc9a098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81e832dd-5072-44f9-ba60-492a8ec114e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=model_dir,\n",
    "                                  evaluation_strategy=\"epoch\", \n",
    "                                  per_device_train_batch_size=16,\n",
    "                                  num_train_epochs=3,\n",
    "                                  logging_steps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5095b2-9063-4c73-bba3-86cfa9e2b189",
   "metadata": {},
   "source": [
    "## 开始训练\n",
    "\n",
    "### 实例化训练器（Trainer）\n",
    "\n",
    "`kernel version` 版本问题：暂不影响本示例代码运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c331656-7b7b-4da4-b101-a86d6fe05d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d800570d-1bc0-47ee-9255-d30dc1100171",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Trainer' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Trainer' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "trainer.device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88355170-ce74-4586-b2dd-73f6465e64fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan 28 21:35:21 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 537.70                 Driver Version: 537.70       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060 Ti   WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| 30%   29C    P2              40W / 200W |   1414MiB /  8192MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1336    C+G   ...crosoft\\Edge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A      1980    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "|    0   N/A  N/A      2272    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A      2952    C+G   ...ke6\\Win32\\HPEnhancedLighting.Bg.exe    N/A      |\n",
      "|    0   N/A  N/A      5104    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A      7496    C+G   ...5\\extracted\\runtime\\WeChatAppEx.exe    N/A      |\n",
      "|    0   N/A  N/A      8840    C+G   ...oogle\\Chrome\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     10528    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A     10552    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11048    C+G   ...n\\120.0.2210.144\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     12596    C+G   C:\\Program Files\\wolai\\wolai.exe          N/A      |\n",
      "|    0   N/A  N/A     12692    C+G   ...App\\OmenCommandCenterBackground.exe    N/A      |\n",
      "|    0   N/A  N/A     13372    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     13996    C+G   ...tility\\HPSystemEventUtilityHost.exe    N/A      |\n",
      "|    0   N/A  N/A     15788    C+G   ...cal\\Microsoft\\OneDrive\\OneDrive.exe    N/A      |\n",
      "|    0   N/A  N/A     16960    C+G   ...50.0_x64__v10z8vjag6ke6\\HP.myHP.exe    N/A      |\n",
      "|    0   N/A  N/A     17740    C+G   ...meCenter\\dlls\\wgc_renderer_host.exe    N/A      |\n",
      "|    0   N/A  N/A     18232    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     19900    C+G   D:\\Microsoft VS Code\\Code.exe             N/A      |\n",
      "|    0   N/A  N/A     24336      C   D:\\anaconda3\\python.exe                   N/A      |\n",
      "|    0   N/A  N/A     24540    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b44665-0c27-40be-a7cb-2c7104c79bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "D:\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 189\n",
      "  Number of trainable parameters = 108314117\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  6/189 00:23 < 18:15, 0.17 it/s, Epoch 0.08/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3be666-06e6-45d8-a1ee-b62c6adfbf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=64).select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b564aa6-0aa5-4bda-95c1-cef3bd255d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(small_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4b837c-d711-4dfe-8ad4-31d1b7476e28",
   "metadata": {},
   "source": [
    "### 保存模型和训练状态\n",
    "\n",
    "- 使用 `trainer.save_model` 方法保存模型，后续可以通过 from_pretrained() 方法重新加载\n",
    "- 使用 `trainer.save_state` 方法保存训练状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7e6f95-206e-4c2e-a922-85c6002a8b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf71d13d-901e-4a92-aff4-830110d176b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_state()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
