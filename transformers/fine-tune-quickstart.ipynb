{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ec8de0d-75af-43df-abf7-05d4e744ca0f",
   "metadata": {},
   "source": [
    "# Hugging Face Transformers 微调训练入门\n",
    "\n",
    "本示例将介绍基于 Transformers 实现模型微调训练的主要流程，包括：\n",
    "- 数据集下载\n",
    "- 数据预处理\n",
    "- 训练超参数配置\n",
    "- 训练评估指标设置\n",
    "- 训练器基本介绍\n",
    "- 实战训练\n",
    "- 模型保存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31188fb-d5ed-438d-911c-6ce92489003a",
   "metadata": {},
   "source": [
    "## YelpReviewFull 数据集\n",
    "\n",
    "**Hugging Face 数据集：[ YelpReviewFull ](https://huggingface.co/datasets/yelp_review_full)**\n",
    "\n",
    "### 数据集摘要\n",
    "\n",
    "Yelp评论数据集包括来自Yelp的评论。它是从Yelp Dataset Challenge 2015数据中提取的。\n",
    "\n",
    "### 支持的任务和排行榜\n",
    "文本分类、情感分类：该数据集主要用于文本分类：给定文本，预测情感。\n",
    "\n",
    "### 语言\n",
    "这些评论主要以英语编写。\n",
    "\n",
    "### 数据集结构\n",
    "\n",
    "#### 数据实例\n",
    "一个典型的数据点包括文本和相应的标签。\n",
    "\n",
    "来自YelpReviewFull测试集的示例如下：\n",
    "\n",
    "```json\n",
    "{\n",
    "    'label': 0,\n",
    "    'text': 'I got \\'new\\' tires from them and within two weeks got a flat. I took my car to a local mechanic to see if i could get the hole patched, but they said the reason I had a flat was because the previous patch had blown - WAIT, WHAT? I just got the tire and never needed to have it patched? This was supposed to be a new tire. \\\\nI took the tire over to Flynn\\'s and they told me that someone punctured my tire, then tried to patch it. So there are resentful tire slashers? I find that very unlikely. After arguing with the guy and telling him that his logic was far fetched he said he\\'d give me a new tire \\\\\"this time\\\\\". \\\\nI will never go back to Flynn\\'s b/c of the way this guy treated me and the simple fact that they gave me a used tire!'\n",
    "}\n",
    "```\n",
    "\n",
    "#### 数据字段\n",
    "\n",
    "- 'text': 评论文本使用双引号（\"）转义，任何内部双引号都通过2个双引号（\"\"）转义。换行符使用反斜杠后跟一个 \"n\" 字符转义，即 \"\\n\"。\n",
    "- 'label': 对应于评论的分数（介于1和5之间）。\n",
    "\n",
    "#### 数据拆分\n",
    "\n",
    "Yelp评论完整星级数据集是通过随机选取每个1到5星评论的130,000个训练样本和10,000个测试样本构建的。总共有650,000个训练样本和50,000个测试样本。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0600af-4896-4612-954b-7c8fe8772b30",
   "metadata": {},
   "source": [
    "## 下载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0550f91e-caed-4c01-aea9-142022d22d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b6326b8-d6c0-482d-9ceb-f03beee0105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 65w条训练数据 5w条测试数据\n",
    "\n",
    "dataset = load_dataset('yelp_review_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea54e5ac-32e4-4d8b-949b-832aa1635b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 650000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "889587f2-31ca-43d0-9e99-6cbbfe511bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 4,\n",
       " 'text': \"dr. goldberg offers everything i look for in a general practitioner.  he's nice and easy to talk to without being patronizing; he's always on time in seeing his patients; he's affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first.  really, what more do you need?  i'm sitting here trying to think of any complaints i have about him, but i'm really drawing a blank.\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffc15d2b-2cba-498e-8997-7ab395fe82f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datasets\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70cf5ccd-4255-40c3-92ab-23bbec8f0143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_elements(dataset, num_examples=10):\n",
    "    # '如果随机抽取的长度如果大于dataset长度则报错'\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    # picks = []\n",
    "    # for _ in range(num_examples):\n",
    "    #     # 随机在0-数据长度之间选择一个\n",
    "    #     pick = random.randint(0,dataset.num_rows-1)\n",
    "    #     # 如果在picks中出现过，则从新选择一个,直到没有在picks中出现过\n",
    "    #     while pick in picks:\n",
    "    #         pick = random.randint(0,dataset.num_rows-1)\n",
    "    #     picks.append(pick)\n",
    "    picks = np.random.choice(dataset.num_rows-1, size=num_examples, replace=False).tolist()\n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    \n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i:typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b669fbc-1b8a-48f0-8479-91deb9cee24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3 stars</td>\n",
       "      <td>The other day I stopped into Dillon's on Central Avenue just off of the canal.  I typically ride my bike by that location at least once a week, so this time I decided to stop by for lunch.  The atmosphere was different than I had expected.   It was designed in a Hollywood kitsch design to give it the atmosphere on a New York/L.A. style deli (outside of New York/L.A.) which was bizarre.   I want barbeque, not deli!\\nThe dining area was nice - clean, nice furniture, etc.  However, it did not feel like a barbeque place.  The crowd was mainly older (60+) on a Saturday afternoon.  I did not fit in with my bike apparel, Nook and cell phone.  \\nThe service was good, not great.  I do not want to be too harsh in saying that the older customers got most of the attention.  I hardly got noticed.  Not that I require constant nurturing, but just fill my ice tea!\\n\\nThe food was very good.   I got a beef brisket sandwich with mashed potatoes and a side of gravy.  Also, I could not resist the $1.00 plate of onion rings.  I was satisfied.  It was done just right and not loaded with salt that keeps you thirsty for hours on end.  I thought the meal was pricey for what I received - no not the onion rings, but a $10.00 sandwich!\\n\\nWhen my check arrived they forgot to include a pen for me.  I waited patiently for the waitress to return, but was somewhat frustrated.\\n\\nI would say it was good, but I would not rush back.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5 stars</td>\n",
       "      <td>Vancouver could take a hint from these guys, they sure know how to do Lebanese food. For under $5 you can get a hearty wrap or for under $10 you can choose up to 5 items from their delicious array of grilled eggplant, sauteed cauliflower, falafel, garlic potatoes and many meaty delights.\\nNo matter how broke you are this place will treat you right and keep you coming back for more.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5 stars</td>\n",
       "      <td>OMG, what can I say?! \\n\\nI have a reluctant sweet tooth but that's not a problem here where you can have the most delicious kick-arse hot chocolate with chilli ever, I'm still thinking about it this morning! \\n\\nThe only problem here is trying to decide which chocolates to buy and not wanting to buy them for everyone you know! \\n\\nAs Arnie said, I'll be back....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3 stars</td>\n",
       "      <td>I cannot recall the number of times I have been here. But, it sure has been a lot. The food here is slightly inconsistent at times, but mostly really good. I wish the owners had thought about expanding the place, as it is too cramped right now. Absolutely love the chole bhature. This is the most authentic chole bhature you can find anywhere in Tempe. The only problem with this establishment is the staff at the counter. I always find them a bit rude and disinterested in customer service.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 star</td>\n",
       "      <td>The food is decent for the neighborhood, but the customer service needs some serious help. I asked the hostess if I needed to put my name on the list for the bar area. She stated \\\"first come first serve.\\\" The first table in bar area that came open I sat down and the bartender asked me to please get up that people were waiting for the table.  He said what the hostess stated was true, but he had his \\\"own list\\\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4 stars</td>\n",
       "      <td>Still Love this place!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1 star</td>\n",
       "      <td>I am totally disgusted with this restaurant. \\n\\nI first visited this restaurant last weekend after hearing good things about their food. My visit was enjoyable- the food was delicious and tasted like it was made from scratch. The waitress was nice and the prices were reasonable. I was excited about my visit so I told invited a friend to join me the following weekend.\\n\\nMy friend and I went for breakfast this morning (now a week later) and it was like I went to an entirely different restaurant. The place was busy but we were able to get a table immediately. The waitress was in a bad mood from the time we sat down. My friend ordered coffee and juice and the waitress looked at her like she was crazy. She came back 3 times within 5 minutes to ask if we were ready to order after we told her we needed time. She was annoyed that my friend needed more time and then asked a question about the menu. I know it must have been terribly inconvenient for the waitress to do her job. The food came out in about 20-30 minutes. The food tasted good, just like my last visit. When we were only half way through our food, she brought us our bill and asked us if we needed anything else. We told her we were fine, but were just finishing our food and chatting. She came by 5 times in 10 minutes asking if we needed anything else so we would hurry up and pay the bill and leave. She had another waitress come ask us if we needed anything else within those 10 minutes as well. Then, my friend took out her card and had it on the table and I was getting out my card and the manager came and without saying a word grabbed the bill and walked away. I tried to stop him but he wouldn't turn around. I had to flag down the waitress to bring our bill back as we had two separate bills and my card hadn't been added yet. Then, the hostess, who is probably the snootiest young lady I've ever met came and said \\\"can I take this\\\" referring to the book t hat the bill is held in and didn't wait for a response before grabbing it and walking away. She came back saying she needed the other receipt and I told her I wasn't done yet but I would leave it when I was. I could see the manager, and several of the staff pointing and talking about us (on more than one occasion) at the hostess station which was 3 booths away.  I have never felt so bullied at a restaurant in my entire life!\\n\\nSince when is it a crime to talk with your party when you are out a restaurant? We were only there for about 1 1/2 hours from the time we sat down to the time we left which is not an exuberant amount of time. Furthermore, there were many open tables elsewhere. Regardless of whether there are tables open or not, there is no reason for a restaurant staff to bother guests to get them to leave. The manager has no place in management. \\n\\nThe only reason my waitress got a tip was so the hard working buser got a portion of the money. She certainly didn't deserve one.\\n\\nThe restaurant deserves an F in manners, customers service, atmosphere, hospitality, and professionalism. I'm completely embarrassed that I spoke so highly of it to my friend who had to experience such terrible and rude service. \\n\\nGood luck staying open.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1 star</td>\n",
       "      <td>Yes, super over priced! Like most people, the buffet line was too long so had to eat here. The place is nice, but the food and service sucks.\\n\\nThe hostess skirt is so short that just standing I can almost see something I don't need to see.\\n\\nThe noodles were oily, the XLB were disgusting, most items lacked flavor. The one decent thing was the beef pancake.\\n\\nAlso our waitress tried to be nice, but she was up in our face. She would come to our table and stand there for a few seconds, stare at us then say something. I really wanted green onion pancake. It took forever to come. I asked twice where is my green onion pancake. The people there kept saying it's coming. Finally everyone was done eating and still no green onion pancake. I complained and the stupid lady goes \\\"oh you ordered that?\\\" I was so mad, she can see the red in my eyes and then she switced to nice mode saying how sorry she is and she will put in the order now. I said no, I want the check so I can leave. She kept saying it will be ready. I'm like NO! \\n\\nBad service! A little too late to fix anything.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1 star</td>\n",
       "      <td>My friends strangely loved going to QQ Asian Buffet, but I haven't the slightest clue as to why they'd trek all the way from downtown and west side Madison to this remote place. Maybe I lied. They probably just loved the notion of all-you-can-eat for $10, and taking a break from their frequent Fugu and Saigon adventures. \\n\\nBut I myself hated it and dreaded having to go to QQ Asian Buffet all the time. Sure, $10 for a buffet dinner is great. But you get what you pay for, so what kind of quality will you expect? So, I'll admit the selection of foods here isn't under par. But their sushi is terrible, their Chinese foods are really oily and greasy, and their American food is unappetizing. I'm probably not alone in thinking this way because every time I've been to QQ Asian Buffet, there were lots of empty tables.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3 stars</td>\n",
       "      <td>Convenience for a reasonable price,,,thats it.. no frills.......Best location</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(dataset['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbb5b6b-474b-4a37-bfc8-d3ccfa99c22f",
   "metadata": {},
   "source": [
    "## 预处理数据\n",
    "\n",
    "下载数据集到本地后，使用 Tokenizer 来处理文本，对于长度不等的输入数据，可以使用填充（padding）和截断（truncation）策略来处理。\n",
    "\n",
    "Datasets 的 `map` 方法，支持一次性在整个数据集上应用预处理函数。\n",
    "\n",
    "下面使用填充到最大长度的策略，处理整个数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89d32c0f-24df-4a1f-bf63-909d35bfb6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ad57601-91e7-44a4-9ae0-7b0578c0f058",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02cf5235-1809-4eb9-ae47-cd52a866e06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c39add39-873c-473b-9318-051c62a70318",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5e53258-b62f-448d-b307-072239be9d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 star</td>\n",
       "      <td>Oh my...  really having a difficult time with this because we love our Veterinarian, Dr. Foster. We however were faced with one of the worst customer service situations today with one of their staff. Kimberly (who referred to herself as a vet-tech) was just horribly, horribly rude and invited us to seek out the services of a different vet. Our dog Charlie has had to go in every couple of months to have her thyroid levels checked as it runs low and is on medication. We have been working with Dr. Foster in keeping in at the level it should. So far frequent blood draws and changes in medication dosages. 2 weeks ago was her last blood draw and results and treatment have been withheld from us. Apparently the presiding vet is the only vet allowed to interpret the results regardless that their are other vets that are on staff that could interpret the results. Vets went on vacation, vets had days off and as yet we still have no results. we have had to schedule another meeting with our vet in order to hear the results.\\nThe earliest they seem to be able to do this is 3 weeks from the date the blood was drawn. Needless to say staff can destroy a business. We as consumers fund the company, create jobs for people and ultimately pay the salaries.</td>\n",
       "      <td>[101, 2048, 1139, 119, 119, 119, 1541, 1515, 170, 2846, 1159, 1114, 1142, 1272, 1195, 1567, 1412, 159, 24951, 2983, 5476, 117, 1987, 119, 7895, 119, 1284, 1649, 1127, 3544, 1114, 1141, 1104, 1103, 4997, 8132, 1555, 7832, 2052, 1114, 1141, 1104, 1147, 2546, 119, 26564, 113, 1150, 2752, 1106, 1941, 1112, 170, 1396, 1204, 118, 13395, 114, 1108, 1198, 16358, 14791, 4999, 117, 16358, 14791, 4999, 14708, 1105, 4022, 1366, 1106, 5622, 1149, 1103, 1826, 1104, 170, 1472, 1396, 1204, 119, 3458, 3676, 4117, 1144, 1125, 1106, 1301, 1107, 1451, 2337, 1104, 1808, 1106, 1138, 1123, 21153, 16219, 3001, ...]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(tokenized_datasets['train'], num_examples=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d94fe3-6794-4103-9a63-e22726d1ec8c",
   "metadata": {},
   "source": [
    "### 数据抽样\n",
    "\n",
    "使用 1000 个数据样本，在 BERT 上演示小规模训练（基于 Pytorch Trainer）\n",
    "\n",
    "`shuffle()`函数会随机重新排列列的值。如果您希望对用于洗牌数据集的算法有更多控制，可以在此函数中指定generator参数来使用不同的numpy.random.Generator。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6de11e5b-3474-4e0a-bd00-b95ee2a6b38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(10000))\n",
    "# small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc690a40-af4d-496d-ae67-515b73c0fbc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_train_dataset.num_rows, small_eval_dataset.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230596f7-eb0c-43f0-bf9e-4a944a9afefe",
   "metadata": {},
   "source": [
    "## 微调训练配置\n",
    "\n",
    "### 加载 BERT 模型\n",
    "\n",
    "警告通知我们正在丢弃一些权重（`vocab_transform` 和 `vocab_layer_norm` 层），并随机初始化其他一些权重（`pre_classifier` 和 `classifier` 层）。在微调模型情况下是绝对正常的，因为我们正在删除用于预训练模型的掩码语言建模任务的头部，并用一个新的头部替换它，对于这个新头部，我们没有预训练的权重，所以库会警告我们在用它进行推理之前应该对这个模型进行微调，而这正是我们要做的事情。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "407777bc-ab63-4af8-9e13-c8b035a60f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7130c597-3306-4e12-b570-54080f5a0843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-cased', num_labels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77de2766-1b89-4a33-ba6c-6094b57975e3",
   "metadata": {},
   "source": [
    "### 训练超参数（TrainingArguments）\n",
    "\n",
    "完整配置参数与默认值：https://huggingface.co/docs/transformers/v4.36.1/en/main_classes/trainer#transformers.TrainingArguments\n",
    "\n",
    "源代码定义：https://github.com/huggingface/transformers/blob/v4.36.1/src/transformers/training_args.py#L161\n",
    "\n",
    "**最重要配置：模型权重保存路径(output_dir)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "279f4915-bfae-498d-a090-6c980abd1746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40175704-a8b9-459f-9b4d-ff20c9f34707",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"models/bert-base-cased-finetune-yelp\"\n",
    "# logging_steps 默认值为500，根据我们的训练数据和步长，将其设置为100\n",
    "# output_dir 保存训练过程中产生的模型和其他输出的目录。\n",
    "# num_train_epochs: 训练的轮次数。\n",
    "# per_device_train_batch_size: 每个设备上的训练批量大小\n",
    "# per_device_eval_batch_size: 每个设备上的评估批量大小。\n",
    "# warmup_steps: 预热步骤的数量，在这些步骤中学习率逐渐增加。\n",
    "# weight_decay: 权重衰减的比例，用于防止过拟合\n",
    "# logging_dir: 存储日志文件的目录。\n",
    "# logging_steps: 每多少步记录一次日志。\n",
    "# save_steps: 每多少步保存一次模型。\n",
    "# eval_steps: 每多少步进行一次评估。\n",
    "# evaluation_strategy: 评估策略，可以是 \"no\"、\"steps\"、\"epoch\" 等。\n",
    "# learning_rate: 初始学习率。\n",
    "# load_best_model_at_end: 训练结束时是否加载最佳模型。\n",
    "# metric_for_best_model: 用于评估最佳模型的指标。\n",
    "# greater_is_better: 在选择最佳模型时，指标的较大值是否表示更好的模型。\n",
    "# save_total_limit: 保存的模型总数限制，超过此限制将删除旧模型。\n",
    "# seed: 随机种子，用于确保结果的可重复性。\n",
    "# fp16: 是否使用半精度浮点数训练（仅在支持的硬件上有效）。\n",
    "\n",
    "training_args = TrainingArguments(output_dir=model_dir,\n",
    "                                  per_device_train_batch_size=8,\n",
    "                                  num_train_epochs=5,\n",
    "                                  logging_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c40e6a1-a21c-42e4-adbe-aba170cd133d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=passive,\n",
      "log_on_each_node=True,\n",
      "logging_dir=models/bert-base-cased-finetune-yelp\\runs\\Jan28_21-34-52_AnMin,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=100,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=5,\n",
      "optim=adamw_hf,\n",
      "output_dir=models/bert-base-cased-finetune-yelp,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=models/bert-base-cased-finetune-yelp,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=steps,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 完整的超参数配置\n",
    "print(training_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2350153-1004-4443-bbd0-18f100ff1116",
   "metadata": {},
   "source": [
    "### 训练过程中的指标评估（Evaluate)\n",
    "\n",
    "**[Hugging Face Evaluate 库](https://huggingface.co/docs/evaluate/index)** 支持使用一行代码，获得数十种不同领域（自然语言处理、计算机视觉、强化学习等）的评估方法。 当前支持 **完整评估指标：https://huggingface.co/evaluate-metric**\n",
    "\n",
    "训练器（Trainer）在训练过程中不会自动评估模型性能。因此，我们需要向训练器传递一个函数来计算和报告指标。 \n",
    "\n",
    "Evaluate库提供了一个简单的准确率函数，您可以使用`evaluate.load`函数加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1182a85e-c82d-4b07-97f0-d5285af5a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d1c9063-8020-4dee-87de-1e09e5a5860c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd5bf0e-24b3-4cae-8d48-526d3fe336ed",
   "metadata": {},
   "source": [
    "接着，调用 `compute` 函数来计算预测的准确率。\n",
    "\n",
    "在将预测传递给 compute 函数之前，我们需要将 logits 转换为预测值（**所有Transformers 模型都返回 logits**）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c09fbac8-dcc7-4d19-ae11-32aed09742e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb8d88e-2475-4d59-9084-1aca00d9479e",
   "metadata": {},
   "source": [
    "#### 训练过程指标监控\n",
    "\n",
    "通常，为了监控训练过程中的评估指标变化，我们可以在`TrainingArguments`指定`evaluation_strategy`参数，以便在 epoch 结束时报告评估指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11cdbc08-9ec4-4a30-989d-3d68bc9a098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81e832dd-5072-44f9-ba60-492a8ec114e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"models/bert-base-cased-finetune-yelp\"\n",
    "training_args = TrainingArguments(output_dir=model_dir,\n",
    "                                  evaluation_strategy=\"epoch\", \n",
    "                                  per_device_train_batch_size=16,\n",
    "                                  num_train_epochs=3,\n",
    "                                  logging_steps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5095b2-9063-4c73-bba3-86cfa9e2b189",
   "metadata": {},
   "source": [
    "## 开始训练\n",
    "\n",
    "### 实例化训练器（Trainer）\n",
    "\n",
    "`kernel version` 版本问题：暂不影响本示例代码运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c331656-7b7b-4da4-b101-a86d6fe05d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88355170-ce74-4586-b2dd-73f6465e64fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan 29 13:53:32 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.108.03   Driver Version: 510.108.03   CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-DGXS...  Off  | 00000000:07:00.0  On |                    0 |\n",
      "| N/A   38C    P0    53W / 300W |   1863MiB / 32768MiB |      5%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-DGXS...  Off  | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    38W / 300W |      4MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-DGXS...  Off  | 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    38W / 300W |      4MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-DGXS...  Off  | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    38W / 300W |      4MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      3481      G   /usr/lib/xorg/Xorg                 24MiB |\n",
      "|    0   N/A  N/A      3516      G   /usr/bin/gnome-shell              118MiB |\n",
      "|    0   N/A  N/A      5268      G   /usr/lib/xorg/Xorg                330MiB |\n",
      "|    0   N/A  N/A      5414      G   /usr/bin/gnome-shell               36MiB |\n",
      "|    0   N/A  N/A      7655      C   ...envs/GPU-torch/bin/python     1277MiB |\n",
      "|    0   N/A  N/A     20165      G   ...RendererForSitePerProcess       36MiB |\n",
      "|    0   N/A  N/A     22741      G   ...el/lib/stage_ros/stageros       11MiB |\n",
      "|    0   N/A  N/A     25940      G   /usr/lib/firefox/firefox           21MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83b44665-0c27-40be-a7cb-2c7104c79bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/anaconda3/envs/GPU-torch/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='471' max='471' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [471/471 05:08, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.056300</td>\n",
       "      <td>1.077750</td>\n",
       "      <td>0.539000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.916200</td>\n",
       "      <td>0.922774</td>\n",
       "      <td>0.598000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.779900</td>\n",
       "      <td>0.931847</td>\n",
       "      <td>0.594000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/anaconda3/envs/GPU-torch/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/raid/anaconda3/envs/GPU-torch/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=471, training_loss=1.0160937987568526, metrics={'train_runtime': 316.2455, 'train_samples_per_second': 94.863, 'train_steps_per_second': 1.489, 'total_flos': 7893544273920000.0, 'train_loss': 1.0160937987568526, 'epoch': 3.0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f3be666-06e6-45d8-a1ee-b62c6adfbf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=64).select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b564aa6-0aa5-4bda-95c1-cef3bd255d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/anaconda3/envs/GPU-torch/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0364636182785034,\n",
       " 'eval_accuracy': 0.52,\n",
       " 'eval_runtime': 0.6256,\n",
       " 'eval_samples_per_second': 159.858,\n",
       " 'eval_steps_per_second': 6.394,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(small_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4b837c-d711-4dfe-8ad4-31d1b7476e28",
   "metadata": {},
   "source": [
    "### 保存模型和训练状态\n",
    "\n",
    "- 使用 `trainer.save_model` 方法保存模型，后续可以通过 from_pretrained() 方法重新加载\n",
    "- 使用 `trainer.save_state` 方法保存训练状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7e6f95-206e-4c2e-a922-85c6002a8b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf71d13d-901e-4a92-aff4-830110d176b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_state()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
